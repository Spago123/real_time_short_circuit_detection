@article{GONI2023100107,
title = {Fast and Accurate Fault Detection and Classification in Transmission Lines using Extreme Learning Machine},
journal = {e-Prime - Advances in Electrical Engineering, Electronics and Energy},
volume = {3},
pages = {100107},
year = {2023},
issn = {2772-6711},
doi = {https://doi.org/10.1016/j.prime.2023.100107},
url = {https://www.sciencedirect.com/science/article/pii/S2772671123000025},
author = {Md.Omaer Faruq Goni and Md. Nahiduzzaman and Md.Shamim Anower and Md.Mahabubur Rahman and Md.Robiul Islam and Mominul Ahsan and Julfikar Haider and Mohammad Shahjalal},
keywords = {Transmission line, Fault detection, Fault classification, Extreme learning machine, Matlab simulink},
abstract = {To provide stability and a continuous supply of power, the detection and classification of faults in the transmission lines (TLs) are crucial in this modern age. It is required to remove a faulty section from a healthy section to provide safety and to minimize power loss due to the fault. In the contemporary world, machine learning (ML) is extensively used in every aspect of life. In this study, a spontaneous fault detection (FD) and fault classification (FC) system based on ML has been proposed. MATLAB Simulink was employed to simulate two different TLs and to generate normal and fault data (Per unit voltage and current) of ten different types. TL-1 consisted of a single generator and a single load whereas TL-2 consisted of two generators and three loads. Upon normalizing the data, an extreme learning machine (ELM) algorithm was used as the classifier. Two different ELM models were developed for FD and FC purposes through training. The method achieved fault classification accuracies of 99.18% and 99.09% for the TL-1 and TL-2 respectively. On the other hand, fault detection accuracies of 99.53% and 99.60% were achieved for the TL-1 and TL-2. The proposed ELM model compared to a traditional artificial neural network (ANN) model demonstrated relatively a shorter processing time and reduced computational complexity. In addition, the proposed method outperformed the existing state-of-the-art methods.}
}

@article{HUANG2006489,
title = {Extreme learning machine: Theory and applications},
journal = {Neurocomputing},
volume = {70},
number = {1},
pages = {489-501},
year = {2006},
note = {Neural Networks},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2005.12.126},
url = {https://www.sciencedirect.com/science/article/pii/S0925231206000385},
author = {Guang-Bin Huang and Qin-Yu Zhu and Chee-Kheong Siew},
keywords = {Feedforward neural networks, Back-propagation algorithm, Extreme learning machine, Support vector machine, Real-time learning, Random node},
abstract = {It is clear that the learning speed of feedforward neural networks is in general far slower than required and it has been a major bottleneck in their applications for past decades. Two key reasons behind may be: (1) the slow gradient-based learning algorithms are extensively used to train neural networks, and (2) all the parameters of the networks are tuned iteratively by using such learning algorithms. Unlike these conventional implementations, this paper proposes a new learning algorithm called extreme learning machine (ELM) for single-hidden layer feedforward neural networks (SLFNs) which randomly chooses hidden nodes and analytically determines the output weights of SLFNs. In theory, this algorithm tends to provide good generalization performance at extremely fast learning speed. The experimental results based on a few artificial and real benchmark function approximation and classification problems including very large complex applications show that the new algorithm can produce good generalization performance in most cases and can learn thousands of times faster than conventional popular learning algorithms for feedforward neural networks.11For the preliminary idea of the ELM algorithm, refer to “Extreme Learning Machine: A New Learning Scheme of Feedforward Neural Networks”, Proceedings of International Joint Conference on Neural Networks (IJCNN2004), Budapest, Hungary, 25–29 July, 2004.}
}